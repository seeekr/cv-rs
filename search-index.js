var searchIndex = {};
searchIndex["cv"] = {"doc":"This library primarily provides a binding and API for OpenCV 3.x.","items":[[0,"core","cv","Core data structures in OpenCV",null,null],[3,"KeyPoint","cv::core","Data structure for salient point detectors",null,null],[12,"point","","Coordinates of the keypoint",0,null],[12,"size","","Diameter of the meaningful keypoint neighborhood",0,null],[12,"angle","","Computed orientation of the keypoint (-1 if not applicable); it's in [0,360) degrees and measured relative to image coordinate system, ie in clockwise.",0,null],[12,"response","","The response by which the most strong keypoints have been selected. Can be used for the further sorting or subsampling",0,null],[12,"octave","","Octave (pyramid layer) from which the keypoint has been extracted",0,null],[12,"class_id","","Object class (if the keypoints need to be clustered by an object they belong to)",0,null],[3,"Scalar","","A 4-element struct that is widely used to pass pixel values.",null,null],[3,"Point2i","","2D integer points specified by its coordinates `x` and `y`.",null,null],[12,"x","","x coordinate",1,null],[12,"y","","y coordinate",1,null],[3,"Point2f","","2D floating points specified by its coordinates `x` and `y`.",null,null],[12,"x","","x coordinate",2,null],[12,"y","","y coordinate",2,null],[3,"Size2i","","`Size2i` struct is used for specifying the size of an image or rectangle with integer dimensions.",null,null],[12,"width","","width",3,null],[12,"height","","height",3,null],[3,"Size2f","","`Size2f` struct is used for specifying the size of an image or rectangle with float dimensions.",null,null],[12,"width","","width",4,null],[12,"height","","height",4,null],[3,"Rect","","The `Rect` defines a rectangle in integer.",null,null],[12,"x","","x coordinate of the left-top corner",5,null],[12,"y","","y coordinate of the left-top corner",5,null],[12,"width","","width of this rectangle",5,null],[12,"height","","height of this rectangle",5,null],[3,"Rect2f","","The `Rect2f` are rectangles in float.",null,null],[12,"x","","x coordinate of the left-top corner",6,null],[12,"y","","y coordinate of the left-top corner",6,null],[12,"width","","width of this rectangle",6,null],[12,"height","","height of this rectangle",6,null],[3,"RotatedRect","","This struct represents a rotated (i.e. not up-right) rectangle. Each rectangle is specified by the center point (mass center), length of each side (represented by `Size2f`) and the rotation angle in degrees.",null,null],[3,"TermCriteria","","Termination criteria for iterative algorithms.",null,null],[4,"LineType","","Line type",null,null],[13,"Filled","","Default type",7,null],[13,"Line4","","4-connected line",7,null],[13,"Line8","","8-connected line",7,null],[13,"LineAA","","antialiased line",7,null],[4,"FlipCode","","A flag to specify how to flip the image. see Mat::flip",null,null],[13,"XAxis","","Along x-axis: dst[i, j] = src[src.rows - i - 1, j]",8,null],[13,"YAxis","","Along y-axis: dst[i, j] = src[i, src.cols - j - 1]",8,null],[13,"XYAxis","","Along both axis: dst[i, j] = src[src.rows - i - 1, src.cols - j - 1]",8,null],[4,"CvType","","Here is the `CvType` in an easy-to-read table.",null,null],[13,"Cv8UC1","","8 bit unsigned, single channel (grey image)",9,null],[13,"Cv8SC1","","8 bit signed, single channel (grey image)",9,null],[13,"Cv16UC1","","16 bit unsigned, single channel (grey image)",9,null],[13,"Cv16SC1","","16 bit signed, single channel (grey image)",9,null],[13,"Cv32SC1","","32 bit signed, single channel (grey image)",9,null],[13,"Cv32FC1","","32 bit float, single channel (grey image)",9,null],[13,"Cv64FC1","","32 bit float, single channel (grey image)",9,null],[13,"Cv8UC2","","8 bit, two channel (rarelly seen)",9,null],[13,"Cv8UC3","","8 bit unsigned, three channels (RGB image)",9,null],[13,"Cv8SC3","","8 bit signed, three channels (RGB image)",9,null],[13,"Cv16UC3","","16 bit unsigned, three channels (RGB image)",9,null],[13,"Cv16SC3","","16 bit signed, three channels (RGB image)",9,null],[13,"Cv32SC3","","32 bit signed, three channels (RGB image)",9,null],[13,"Cv32FC3","","32 bit float, three channels (RGB image)",9,null],[13,"Cv64FC3","","32 bit float, three channels (RGB image)",9,null],[4,"NormType","","Normalization type. Please refer to OpenCV's documentation.",null,null],[13,"Inf","","Normalized using `max`",10,null],[13,"L1","","Normalized using L1 distance",10,null],[13,"L2","","Normalized using L2 distance",10,null],[13,"L2Sqr","","Normalized using L2 sqr distance",10,null],[13,"Hamming","","Normalized using hamming distance",10,null],[13,"Hamming2","","Normalized using hamming2 distance",10,null],[13,"Relative","","Normalized using relative distance",10,null],[13,"MinMax","","Normalized using minmax distance",10,null],[4,"TermType","","Term criteria type, can be one of: Count, Eps or Count + Eps",null,null],[13,"Count","","The maximum number of iterations or elements to compute",11,null],[13,"EPS","","the desired accuracy or change in parameters at which the iterative algorithm stops.",11,null],[8,"FromBytes","","Allow self deserialization from byte slice",null,null],[10,"from_bytes","","Deserializes self from byte slice",12,null],[11,"default","","",0,{"o":{"n":"keypoint"}}],[11,"fmt","","",0,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",0,{"i":[{"n":"self"}],"o":{"n":"keypoint"}}],[11,"default","","",13,{"o":{"n":"scalar"}}],[11,"fmt","","",13,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",13,{"i":[{"n":"self"}],"o":{"n":"scalar"}}],[11,"new","","Creates a new scalar object.",13,{"i":[{"n":"c_int"},{"n":"c_int"},{"n":"c_int"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"all","","Creates a new scalar object with all value being the same.",13,{"i":[{"n":"c_int"}],"o":{"n":"self"}}],[11,"default","","",1,{"o":{"n":"point2i"}}],[11,"fmt","","",1,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",1,{"i":[{"n":"self"}],"o":{"n":"point2i"}}],[11,"new","","Creats a new `Point2i`.",1,{"i":[{"n":"c_int"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"default","","",2,{"o":{"n":"point2f"}}],[11,"fmt","","",2,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",2,{"i":[{"n":"self"}],"o":{"n":"point2f"}}],[11,"new","","Creats a new `Point2f`.",2,{"i":[{"n":"f32"},{"n":"f32"}],"o":{"n":"self"}}],[11,"default","","",3,{"o":{"n":"size2i"}}],[11,"fmt","","",3,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",3,{"i":[{"n":"self"}],"o":{"n":"size2i"}}],[11,"new","","Creates a new `Size2i` object with `width` and `height`",3,{"i":[{"n":"c_int"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"default","","",4,{"o":{"n":"size2f"}}],[11,"fmt","","",4,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",4,{"i":[{"n":"self"}],"o":{"n":"size2f"}}],[11,"default","","",5,{"o":{"n":"rect"}}],[11,"fmt","","",5,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",5,{"i":[{"n":"self"}],"o":{"n":"rect"}}],[11,"eq","","",5,{"i":[{"n":"self"},{"n":"rect"}],"o":{"n":"bool"}}],[11,"ne","","",5,{"i":[{"n":"self"},{"n":"rect"}],"o":{"n":"bool"}}],[11,"new","","Creates a new `Rect` with (x, y, width, height) parameters.",5,{"i":[{"n":"c_int"},{"n":"c_int"},{"n":"c_int"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"scale","","Scales the rectangle by the specified ratio.",5,{"i":[{"n":"self"},{"n":"f32"}],"o":{"n":"rect"}}],[11,"normalize_to_mat","","Normalize the rectangle according to the image (if the rectangle is inside the image, then the result should be all within (0, 1).",5,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"rect2f"}}],[11,"default","","",6,{"o":{"n":"rect2f"}}],[11,"fmt","","",6,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",6,{"i":[{"n":"self"}],"o":{"n":"rect2f"}}],[11,"normalize_to_mat","","Normalize the rectangle according to the image. This will restore the Rect in absolute pixel numbers.",6,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"rect"}}],[11,"fmt","","",7,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",7,{"i":[{"n":"self"}],"o":{"n":"linetype"}}],[11,"eq","","",7,{"i":[{"n":"self"},{"n":"linetype"}],"o":{"n":"bool"}}],[11,"hash","","",7,null],[11,"fmt","","",8,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",8,{"i":[{"n":"self"}],"o":{"n":"flipcode"}}],[11,"eq","","",8,{"i":[{"n":"self"},{"n":"flipcode"}],"o":{"n":"bool"}}],[11,"hash","","",8,null],[11,"fmt","","",9,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",9,{"i":[{"n":"self"}],"o":{"n":"cvtype"}}],[11,"eq","","",9,{"i":[{"n":"self"},{"n":"cvtype"}],"o":{"n":"bool"}}],[11,"hash","","",9,null],[11,"default","","",14,{"o":{"n":"rotatedrect"}}],[11,"fmt","","",14,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",14,{"i":[{"n":"self"}],"o":{"n":"rotatedrect"}}],[11,"points","","Return 4 vertices of the rectangle.",14,null],[11,"bounding_rect","","Return the minimal up-right rectangle containing the rotated rectangle",14,{"i":[{"n":"self"}],"o":{"n":"rect"}}],[11,"fmt","","",10,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",10,{"i":[{"n":"self"}],"o":{"n":"normtype"}}],[11,"eq","","",10,{"i":[{"n":"self"},{"n":"normtype"}],"o":{"n":"bool"}}],[11,"hash","","",10,null],[11,"fmt","","",11,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",11,{"i":[{"n":"self"}],"o":{"n":"termtype"}}],[11,"eq","","",11,{"i":[{"n":"self"},{"n":"termtype"}],"o":{"n":"bool"}}],[11,"hash","","",11,null],[11,"fmt","","",15,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates a new termination criteria.",15,{"i":[{"n":"termtype"},{"n":"c_int"},{"n":"f64"}],"o":{"n":"self"}}],[11,"drop","","",15,{"i":[{"n":"self"}]}],[0,"cuda","cv","Bindings to OpenCV's classes and functions that exploits GPU/Cuda. See cv::cuda",null,null],[3,"GpuMat","cv::cuda","`GpuMat` data structure in rust, bound to an opaque type in C/C++.",null,null],[12,"cols","","Number of columns",16,null],[12,"rows","","Number of rows",16,null],[12,"depth","","Depth of this mat",16,null],[3,"GpuHog","","Data structure that performs Histogram of Gradient (HOG).",null,null],[12,"params","","Hog parameters.",17,null],[12,"return_score","","Should return detection scores",17,null],[3,"GpuCascade","","Data structure that performs object detection with a cascade classifier.",null,null],[4,"CGpuMat","","Opaque data struct for C/C++ cv::cuda::GpuMat bindings",null,null],[4,"CGpuHog","","Opaque data struct for C bindings",null,null],[4,"CGpuCascade","","Opaque data struct for C bindings",null,null],[11,"clone","","",18,{"i":[{"n":"self"}],"o":{"n":"cgpumat"}}],[11,"fmt","","",18,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"fmt","","",16,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"default","","Creates a default `GpuMat`.",16,{"o":{"n":"gpumat"}}],[11,"upload","","Uploads a normal `Mat`",16,{"i":[{"n":"self"},{"n":"mat"}]}],[11,"drop","","",16,{"i":[{"n":"self"}]}],[11,"from","","",16,{"i":[{"n":"mat"}],"o":{"n":"gpumat"}}],[11,"clone","","",19,{"i":[{"n":"self"}],"o":{"n":"cgpuhog"}}],[11,"fmt","","",19,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"fmt","","",17,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"detect","","",17,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"vec"}}],[11,"default","","",17,{"o":{"n":"gpuhog"}}],[11,"new","","Creates a new GpuHog detector.",17,{"i":[{"n":"size2i"},{"n":"size2i"},{"n":"size2i"},{"n":"size2i"},{"n":"c_int"}],"o":{"n":"gpuhog"}}],[11,"return_score","","Should or not return the detection score",17,{"i":[{"n":"self"},{"n":"bool"}]}],[11,"with_params","","Creates a new GpuHog detector with parameters specified inside `params`.",17,{"i":[{"n":"hogparams"}],"o":{"n":"gpuhog"}}],[11,"set_svm_detector","","Sets the SVM detector.",17,{"i":[{"n":"self"},{"n":"svmdetector"}]}],[11,"drop","","",17,{"i":[{"n":"self"}]}],[11,"clone","","",20,{"i":[{"n":"self"}],"o":{"n":"cgpucascade"}}],[11,"fmt","","",20,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"fmt","","",21,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"from_path","","Loads the classifier from a file.",21,{"i":[{"n":"p"}],"o":{"g":["error"],"n":"result"}}],[11,"detect_multiscale","","Detects objects of different sizes in the input image.",21,{"i":[{"n":"self"},{"n":"gpumat"}],"o":{"g":["rect"],"n":"vec"}}],[11,"set_find_largest_object","","Sets whether or not to find the only largest object.",21,{"i":[{"n":"self"},{"n":"bool"}]}],[11,"set_max_num_objects","","Sets the maximum number of objects.",21,{"i":[{"n":"self"},{"n":"c_int"}]}],[11,"set_min_neighbors","","Sets minimal neighbors required for a detection to be valid.",21,{"i":[{"n":"self"},{"n":"c_int"}]}],[11,"set_max_object_size","","Sets the maximun object size.",21,{"i":[{"n":"self"},{"n":"size2i"}]}],[11,"set_min_object_size","","Sets the minimal object size.",21,{"i":[{"n":"self"},{"n":"size2i"}]}],[11,"set_scale_factor","","Sets the scale factor used in multiscale detection.",21,{"i":[{"n":"self"},{"n":"f64"}]}],[11,"get_classifier_size","","Returns the classifier size.",21,{"i":[{"n":"self"}],"o":{"n":"size2i"}}],[11,"get_find_largest_object_flag","","Returns if the CascadeClassifier will only return the largest object.",21,{"i":[{"n":"self"}],"o":{"n":"bool"}}],[11,"get_max_num_objects","","Returns the allowed maximal number of detected objects.",21,{"i":[{"n":"self"}],"o":{"n":"c_int"}}],[11,"get_min_neighbors","","Returns the number of minimal neighbors required for a detection to be valid.",21,{"i":[{"n":"self"}],"o":{"n":"c_int"}}],[11,"get_max_object_size","","Returns the maximum object size.",21,{"i":[{"n":"self"}],"o":{"n":"size2i"}}],[11,"get_min_object_size","","Returns the minimal object size.",21,{"i":[{"n":"self"}],"o":{"n":"size2i"}}],[11,"get_scale_factor","","Returns the scale factor.",21,{"i":[{"n":"self"}],"o":{"n":"f64"}}],[11,"detect","","",21,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"vec"}}],[11,"drop","","",21,{"i":[{"n":"self"}]}],[0,"errors","cv","Errors for OpenCV bindings",null,null],[4,"CvError","cv::errors","Custom errors that may happen during calls",null,null],[13,"InvalidPath","","Indicates that path was invalid",22,null],[13,"EntryNotFound","","Indicates that there is no entry on specified path",22,null],[13,"UnknownError","","Indicates that error occurred in C++ code",22,null],[13,"UnicodeChars","","Indicates that string contains non ascii characters",22,null],[11,"fmt","","",22,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[0,"features2d","cv","Provide 2D image feature detectors and descriptor extractors",null,null],[3,"BOWKMeansTrainer","cv::features2d","K-means - based class to train visual vocabulary using the bag of visual words approach",null,null],[3,"DMatch","","Type for matching keypoint descriptors",null,null],[3,"DescriptorMatcher","","Type for matching keypoint descriptors",null,null],[3,"MSER","","Maximally stable extremal region extractor.",null,null],[3,"MSERBuilder","","Builder that provides defaults for MSER",null,null],[3,"SIFT","","Speeded up robust features extractor.",null,null],[3,"SIFTBuilder","","Builder that provides defaults for MSER",null,null],[3,"SURF","","Speeded up robust features extractor.",null,null],[3,"SURFBuilder","","Builder that provides defaults for MSER",null,null],[4,"KMeansCenters","","k-Means centers",null,null],[13,"Random","","Select random initial centers in each attempt.",23,null],[13,"Pp","","Use kmeans++ center initialization by Arthur and Vassilvitskii (Arthur2007).",23,null],[4,"DescriptorMatcherType","","Descriptor matcher type",null,null],[13,"BruteForce","","",24,null],[13,"BruteForceL1","","",24,null],[13,"BruteForceHamming","","",24,null],[13,"BruteForceHamming2","","",24,null],[13,"FlannBased","","",24,null],[11,"fmt","","",25,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"fmt","","",23,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",23,{"i":[{"n":"self"}],"o":{"n":"kmeanscenters"}}],[11,"drop","","",25,{"i":[{"n":"self"}]}],[11,"new","","Creates a new maximally stable extremal region extractor criteria.",25,{"i":[{"n":"i32"},{"n":"termcriteria"},{"n":"i32"},{"n":"kmeanscenters"}],"o":{"n":"self"}}],[11,"add","","Adds descriptors to a training set",25,{"i":[{"n":"self"},{"n":"mat"}]}],[11,"cluster","","Clusters train descriptors",25,{"i":[{"n":"self"}],"o":{"n":"mat"}}],[11,"default","","",26,{"o":{"n":"dmatch"}}],[11,"fmt","","",26,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",26,{"i":[{"n":"self"}],"o":{"n":"dmatch"}}],[11,"fmt","","",24,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",24,{"i":[{"n":"self"}],"o":{"n":"descriptormatchertype"}}],[11,"fmt","","",27,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"drop","","",27,{"i":[{"n":"self"}]}],[11,"new","","Creates a descriptor matcher of a given type with the default parameters (using default constructor).",27,{"i":[{"n":"descriptormatchertype"}],"o":{"n":"descriptormatcher"}}],[11,"add","","Adds descriptors to train a CPU or GPU descriptor collection",27,{"i":[{"n":"self"},{"n":"vec"}]}],[11,"train","","Trains a descriptor matcher",27,{"i":[{"n":"self"}]}],[11,"is_empty","","Returns true if there are no train descriptors",27,{"i":[{"n":"self"}],"o":{"n":"bool"}}],[11,"match_","","Finds the best match for each descriptor from a query set",27,{"i":[{"n":"self"},{"n":"mat"}],"o":{"g":["dmatch"],"n":"vec"}}],[11,"match_two","","Finds the best match for each descriptor from a query set. Unlike `match_`, train descriptors collection are passed directly",27,{"i":[{"n":"self"},{"n":"mat"},{"n":"mat"}],"o":{"g":["dmatch"],"n":"vec"}}],[11,"knn_match","","Finds the k best matches for each descriptor from a query set.",27,{"i":[{"n":"self"},{"n":"mat"},{"n":"usize"}],"o":{"g":["vec"],"n":"vec"}}],[11,"fmt","","",28,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates a new maximally stable extremal region extractor criteria.",28,{"i":[{"n":"c_int"},{"n":"c_int"},{"n":"c_int"},{"n":"f64"},{"n":"f64"},{"n":"c_int"},{"n":"f64"},{"n":"f64"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"detect_regions","","Detect MSER regions.",28,null],[11,"drop","","",28,{"i":[{"n":"self"}]}],[11,"fmt","","",29,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",29,{"i":[{"n":"self"}],"o":{"n":"mserbuilder"}}],[11,"default","","",29,{"o":{"n":"mserbuilder"}}],[11,"delta","","Replace current delta with specified value",29,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"min_area","","Replace current min_area with specified value",29,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"max_area","","Replace current max_area with specified value",29,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"max_variation","","Replace current max_variation with specified value",29,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"min_diversity","","Replace current min_diversity with specified value",29,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"max_evolution","","Replace current max_evolution with specified value",29,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"area_threshold","","Replace current area_threshold with specified value",29,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"min_margin","","Replace current min_margin with specified value",29,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"edge_blur_size","","Replace current edge_blur_size with specified value",29,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"into","","",29,{"i":[{"n":"self"}],"o":{"n":"mser"}}],[11,"fmt","","",30,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates a new maximally stable extremal region extractor criteria.",30,{"i":[{"n":"c_int"},{"n":"c_int"},{"n":"f64"},{"n":"f64"},{"n":"f64"}],"o":{"n":"self"}}],[11,"drop","","",30,{"i":[{"n":"self"}]}],[11,"fmt","","",31,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",31,{"i":[{"n":"self"}],"o":{"n":"siftbuilder"}}],[11,"default","","",31,{"o":{"n":"siftbuilder"}}],[11,"features","","Replace current features with specified value",31,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"octave_layers","","Replace current octave_layers with specified value",31,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"contrast_threshold","","Replace current contrast_threshold with specified value",31,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"edge_threshold","","Replace current edge_threshold with specified value",31,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"sigma","","Replace current sigma with specified value",31,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"into","","",31,{"i":[{"n":"self"}],"o":{"n":"sift"}}],[11,"detect_and_compute","","",30,null],[11,"fmt","","",32,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates a new maximally stable extremal region extractor criteria.",32,{"i":[{"n":"f64"},{"n":"c_int"},{"n":"c_int"},{"n":"bool"},{"n":"bool"}],"o":{"n":"self"}}],[11,"drop","","",32,{"i":[{"n":"self"}]}],[11,"fmt","","",33,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",33,{"i":[{"n":"self"}],"o":{"n":"surfbuilder"}}],[11,"default","","",33,{"o":{"n":"surfbuilder"}}],[11,"hessian_threshold","","Replace current octave_layers with specified value",33,{"i":[{"n":"self"},{"n":"f64"}],"o":{"n":"self"}}],[11,"octaves","","Replace current octave_layers with specified value",33,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"octave_layers","","Replace current octave_layers with specified value",33,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"extended","","Replace current extended with specified value",33,{"i":[{"n":"self"},{"n":"bool"}],"o":{"n":"self"}}],[11,"upright","","Replace current delta with specified value",33,{"i":[{"n":"self"},{"n":"bool"}],"o":{"n":"self"}}],[11,"into","","",33,{"i":[{"n":"self"}],"o":{"n":"surf"}}],[11,"detect_and_compute","","",32,null],[8,"Feature2D","","Basic trait for 2D image feature detectors and descriptor extractors",null,null],[10,"detect_and_compute","","Detects keypoints and computes the descriptors",34,null],[0,"hash","cv","The module brings implementations of different image hashing algorithms.",null,null],[3,"AverageHash","cv::hash","Computes average hash value of the input image",null,null],[3,"BlockMeanHash","","Image hash based on block mean",null,null],[3,"ColorMomentHash","","Image hash based on color moments",null,null],[3,"MarrHildrethHash","","Marr-Hildreth Operator Based Hash, slowest but more discriminative.",null,null],[3,"PHash","","Slower than AverageHash, but tolerant of minor modifications",null,null],[3,"RadialVarianceHash","","Image hash based on Radon transform",null,null],[8,"HashImplInterface","","",null,null],[8,"Hash","","Basic trait for all hash types",null,null],[10,"compute","","Computes image hash",35,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"mat"}}],[10,"compare","","Compares two image hashes",35,{"i":[{"n":"self"},{"n":"mat"},{"n":"mat"}],"o":{"n":"f64"}}],[11,"fmt","","",36,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates new instance",36,{"o":{"n":"self"}}],[11,"drop","","",36,{"i":[{"n":"self"}]}],[11,"fmt","","",37,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates new instance",37,{"o":{"n":"self"}}],[11,"drop","","",37,{"i":[{"n":"self"}]}],[11,"fmt","","",38,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates new instance",38,{"o":{"n":"self"}}],[11,"drop","","",38,{"i":[{"n":"self"}]}],[11,"fmt","","",39,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates new instance",39,{"o":{"n":"self"}}],[11,"drop","","",39,{"i":[{"n":"self"}]}],[11,"fmt","","",40,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates new instance",40,{"o":{"n":"self"}}],[11,"drop","","",40,{"i":[{"n":"self"}]}],[11,"fmt","","",41,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates new instance",41,{"o":{"n":"self"}}],[11,"drop","","",41,{"i":[{"n":"self"}]}],[0,"highgui","cv","highgui: high-level GUI",null,null],[4,"WindowFlag","cv::highgui","Flags for highgui_named_window. This only supports a subset of all cv::WindowFlags because C/C++ allows enum with the same value but Rust is stricter.",null,null],[13,"Normal","","the window can be resized (no constraint) or switched to fullscreen.",42,null],[13,"Autosize","","the window is constrained by the image displayed.",42,null],[13,"Opengl","","the window is with opengl support.",42,null],[13,"FreeRatio","","the window can be resized arbitrarily (no ratio constraint).",42,null],[4,"MouseEventType","","Mouse Events",null,null],[13,"MouseMove","","Indicates that the mouse has moved over the window.",43,null],[13,"LButtonDown","","Indicates that the left mouse button is pressed.",43,null],[13,"RButtonDown","","Indicates that the right mouse button is pressed.",43,null],[13,"MButtonDown","","Indicates that the middle mouse button is pressed.",43,null],[13,"LButtonUp","","Indicates that left mouse button is released.",43,null],[13,"RButtonUp","","Indicates that right mouse button is released.",43,null],[13,"MButtonUp","","Indicates that middle mouse button is released.",43,null],[13,"LButtonClick","","Indicates that left mouse button is double clicked.",43,null],[13,"RButtonClick","","Indicates that right mouse button is double clicked.",43,null],[13,"MButtonClick","","Indicates that middle mouse button is double clicked.",43,null],[13,"MouseWheel","","Positive/negative means forward/backward scrolling.",43,null],[13,"MouseHWheel","","Positive/negative means right and left scrolling.",43,null],[5,"highgui_named_window","","Create a window that can be used as a placeholder for images and trackbars. All created windows are referred to by their names. If a window with the same name already exists, the function does nothing.",null,{"i":[{"n":"str"},{"n":"windowflag"}],"o":{"g":["error"],"n":"result"}}],[5,"highgui_destroy_window","","Destroy the specified window with the given name.",null,{"i":[{"n":"str"}]}],[5,"highgui_set_mouse_callback","","Set mouse handler for the specified window (identified by name). A callback handler should be provided and optional user_data can be passed around.",null,null],[6,"MouseCallbackData","","Pointer referring to the data used in MouseCallback",null,null],[6,"MouseCallback","","Callback function for mouse events, primarily used in highgui_set_mouse_callback",null,null],[8,"Show","","Provides some highgui functionallity",null,null],[10,"show","","Calls out to highgui to show the image, the duration is specified by `delay`.",44,{"i":[{"n":"self"},{"n":"str"},{"n":"c_int"}],"o":{"g":["error"],"n":"result"}}],[11,"fmt","","",42,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",42,{"i":[{"n":"self"}],"o":{"n":"windowflag"}}],[11,"eq","","",42,{"i":[{"n":"self"},{"n":"windowflag"}],"o":{"n":"bool"}}],[11,"hash","","",42,null],[11,"fmt","","",43,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",43,{"i":[{"n":"self"}],"o":{"n":"mouseeventtype"}}],[11,"eq","","",43,{"i":[{"n":"self"},{"n":"mouseeventtype"}],"o":{"n":"bool"}}],[11,"hash","","",43,null],[0,"imgcodecs","cv","Image file reading and writing, see OpenCV imgcodecs.",null,null],[4,"ImageReadMode","cv::imgcodecs","ImreadModes. See documentation for detauls",null,null],[13,"Unchanged","","If set, return the loaded image as is (with alpha channel, otherwise it gets cropped",45,null],[13,"Grayscale","","If set, always convert image to the single channel grayscale image.",45,null],[13,"Color","","If set, always convert image to the 3 channel BGR color image.",45,null],[13,"AnyDepth","","If set, return 16-bit/32-bit image when the input has the corresponding depth, otherwise convert it to 8-bit.",45,null],[13,"AnyColor","","If set, the image is read in any possible color format.",45,null],[13,"LoadGdal","","If set, use the gdal driver for loading the image.",45,null],[13,"ReducedGrayscale2","","If set, always convert image to the single channel grayscale image and the image size reduced 1/2.",45,null],[13,"ReducedColor2","","If set, always convert image to the 3 channel BGR color image and the image size reduced 1/2.",45,null],[13,"ReducedGrayscale4","","If set, always convert image to the single channel grayscale image and the image size reduced 1/4.",45,null],[13,"ReducedColor4","","If set, always convert image to the 3 channel BGR color image and the image size reduced 1/4.",45,null],[13,"ReducedGrayscale8","","If set, always convert image to the single channel grayscale image and the image size reduced 1/8.",45,null],[13,"ReducedColor8","","If set, always convert image to the 3 channel BGR color image and the image size reduced 1/8.",45,null],[4,"ImageWriteMode","","Imwrite flags. See documentation for detauls",null,null],[13,"JpegQuality","","For JPEG, it can be a quality from 0 to 100 (the higher is the better). Default value is 95.",46,null],[13,"JpegProgressive","","Enable JPEG features, 0 or 1, default is False.",46,null],[13,"JpegOptimize","","Enable JPEG features, 0 or 1, default is False.",46,null],[13,"JpegRstInterval","","JPEG restart interval, 0 - 65535, default is 0 - no restart.",46,null],[13,"JpegLumaQuality","","Separate luma quality level, 0 - 100, default is 0 - don't use.",46,null],[13,"JpegChromaQuality","","Separate chroma quality level, 0 - 100, default is 0 - don't use.",46,null],[13,"PngCompression","","For PNG, it can be the compression level from 0 to 9. A higher value means a smaller size and longer compression time. Default value is 3. Also strategy is changed to IMWRITE_PNG_STRATEGY_DEFAULT (Z_DEFAULT_STRATEGY).",46,null],[13,"PngStrategy","","One of cv::ImwritePNGFlags, default is IMWRITE_PNG_STRATEGY_DEFAULT.",46,null],[13,"PngBilevel","","Binary level PNG, 0 or 1, default is 0.",46,null],[13,"PxmBinary","","For PPM, PGM, or PBM, it can be a binary format flag, 0 or 1. Default value is 1.",46,null],[13,"WebpQuality","","For WEBP, it can be a quality from 1 to 100 (the higher is the better). By default (without any parameter) and for quality above 100 the lossless compression is used.",46,null],[13,"PamTupletype","","For PAM, sets the TUPLETYPE field to the corresponding string value that is defined for the format",46,null],[4,"ImageWritePngStrategy","","Imwrite PNG flag. See documentation for detauls",null,null],[13,"Default","","Use this value for normal data.",47,null],[13,"Filtered","","Use this value for data produced by a filter (or predictor).Filtered data consists mostly of small values with a somewhat random distribution. In this case, the compression algorithm is tuned to compress them better.",47,null],[13,"HuffmanOnly","","Use this value to force Huffman encoding only (no string match).",47,null],[13,"RLE","","Use this value to limit match distances to one (run-length encoding).",47,null],[13,"Fixed","","Using this value prevents the use of dynamic Huffman codes, allowing for a simpler decoder for special applications.",47,null],[11,"fmt","","",45,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",45,{"i":[{"n":"self"}],"o":{"n":"imagereadmode"}}],[11,"eq","","",45,{"i":[{"n":"self"},{"n":"imagereadmode"}],"o":{"n":"bool"}}],[11,"hash","","",45,null],[11,"fmt","","",46,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",46,{"i":[{"n":"self"}],"o":{"n":"imagewritemode"}}],[11,"eq","","",46,{"i":[{"n":"self"},{"n":"imagewritemode"}],"o":{"n":"bool"}}],[11,"hash","","",46,null],[11,"fmt","","",47,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",47,{"i":[{"n":"self"}],"o":{"n":"imagewritepngstrategy"}}],[11,"eq","","",47,{"i":[{"n":"self"},{"n":"imagewritepngstrategy"}],"o":{"n":"bool"}}],[11,"hash","","",47,null],[0,"imgproc","cv","Image processing, see OpenCV imgproc.",null,null],[4,"HistogramComparisionMethod","cv::imgproc","Possible methods for histogram comparision method",null,null],[13,"Correlation","","HISTCMP_CORREL",48,null],[13,"ChiSquare","","HISTCMP_CHISQR",48,null],[13,"Intersection","","HISTCMP_INTERSECT",48,null],[13,"Bhattacharyya","","HISTCMP_BHATTACHARYYA and HISTCMP_HELLINGER",48,null],[13,"ChiSquareAlternative","","HISTCMP_CHISQR_ALT",48,null],[13,"KullbackLeiblerDivergence","","HISTCMP_KL_DIV",48,null],[4,"ThresholdType","","ThresholdTypes used in threshold.",null,null],[13,"Binary","","",49,null],[13,"BinaryInv","","",49,null],[13,"Trunc","","",49,null],[13,"ToZero","","",49,null],[13,"ToZeroInv","","",49,null],[13,"Mask","","",49,null],[13,"Otsu","","",49,null],[13,"Triangle","","",49,null],[4,"ColorConversion","","Color conversion code used in cvt_color.",null,null],[13,"BGR2BGRA","","",50,null],[13,"BGRA2BGR","","",50,null],[13,"BGR2RGBA","","",50,null],[13,"RGBA2BGR","","",50,null],[13,"BGR2RGB","","",50,null],[13,"BGRA2RGBA","","",50,null],[13,"BGR2GRAY","","",50,null],[13,"RGB2GRAY","","",50,null],[13,"GRAY2BGR","","",50,null],[13,"GRAY2BGRA","","",50,null],[13,"BGRA2GRAY","","",50,null],[13,"RGBA2GRAY","","",50,null],[13,"BGR2BGR565","","",50,null],[13,"RGB2BGR565","","",50,null],[13,"BGR5652BGR","","",50,null],[13,"BGR5652RGB","","",50,null],[13,"BGRA2BGR565","","",50,null],[13,"RGBA2BGR565","","",50,null],[13,"BGR5652BGRA","","",50,null],[13,"BGR5652RGBA","","",50,null],[13,"GRAY2BGR565","","",50,null],[13,"BGR5652GRAY","","",50,null],[13,"BGR2BGR555","","",50,null],[13,"RGB2BGR555","","",50,null],[13,"BGR5552BGR","","",50,null],[13,"BGR5552RGB","","",50,null],[13,"BGRA2BGR555","","",50,null],[13,"RGBA2BGR555","","",50,null],[13,"BGR5552BGRA","","",50,null],[13,"BGR5552RGBA","","",50,null],[13,"GRAY2BGR555","","",50,null],[13,"BGR5552GRAY","","",50,null],[13,"BGR2XYZ","","",50,null],[13,"RGB2XYZ","","",50,null],[13,"XYZ2BGR","","",50,null],[13,"XYZ2RGB","","",50,null],[13,"BGR2YCrCb","","",50,null],[13,"RGB2YCrCb","","",50,null],[13,"YCrCb2BGR","","",50,null],[13,"YCrCb2RGB","","",50,null],[13,"BGR2HSV","","",50,null],[13,"RGB2HSV","","",50,null],[13,"BGR2Lab","","",50,null],[13,"RGB2Lab","","",50,null],[13,"BGR2Luv","","",50,null],[13,"RGB2Luv","","",50,null],[13,"BGR2HLS","","",50,null],[13,"RGB2HLS","","",50,null],[13,"HSV2BGR","","",50,null],[13,"HSV2RGB","","",50,null],[13,"Lab2BGR","","",50,null],[13,"Lab2RGB","","",50,null],[13,"Luv2BGR","","",50,null],[13,"Luv2RGB","","",50,null],[13,"HLS2BGR","","",50,null],[13,"HLS2RGB","","",50,null],[13,"BGR2HSV_FULL","","",50,null],[13,"RGB2HSV_FULL","","",50,null],[13,"BGR2HLS_FULL","","",50,null],[13,"RGB2HLS_FULL","","",50,null],[13,"HSV2BGR_FULL","","",50,null],[13,"HSV2RGB_FULL","","",50,null],[13,"HLS2BGR_FULL","","",50,null],[13,"HLS2RGB_FULL","","",50,null],[13,"LBGR2Lab","","",50,null],[13,"LRGB2Lab","","",50,null],[13,"LBGR2Luv","","",50,null],[13,"LRGB2Luv","","",50,null],[13,"Lab2LBGR","","",50,null],[13,"Lab2LRGB","","",50,null],[13,"Luv2LBGR","","",50,null],[13,"Luv2LRGB","","",50,null],[13,"BGR2YUV","","",50,null],[13,"RGB2YUV","","",50,null],[13,"YUV2BGR","","",50,null],[13,"YUV2RGB","","",50,null],[13,"YUV2RGB_NV12","","",50,null],[13,"YUV2BGR_NV12","","",50,null],[13,"YUV2RGB_NV21","","",50,null],[13,"YUV2BGR_NV21","","",50,null],[13,"YUV2RGBA_NV12","","",50,null],[13,"YUV2BGRA_NV12","","",50,null],[13,"YUV2RGBA_NV21","","",50,null],[13,"YUV2BGRA_NV21","","",50,null],[13,"YUV2RGB_YV12","","",50,null],[13,"YUV2BGR_YV12","","",50,null],[13,"YUV2RGB_IYUV","","",50,null],[13,"YUV2BGR_IYUV","","",50,null],[13,"YUV2RGBA_YV12","","",50,null],[13,"YUV2BGRA_YV12","","",50,null],[13,"YUV2RGBA_IYUV","","",50,null],[13,"YUV2BGRA_IYUV","","",50,null],[13,"YUV2GRAY_420","","",50,null],[13,"YUV2RGB_UYVY","","",50,null],[13,"YUV2BGR_UYVY","","",50,null],[13,"YUV2RGBA_UYVY","","",50,null],[13,"YUV2BGRA_UYVY","","",50,null],[13,"YUV2RGB_YUY2","","",50,null],[13,"YUV2BGR_YUY2","","",50,null],[13,"YUV2RGB_YVYU","","",50,null],[13,"YUV2BGR_YVYU","","",50,null],[13,"YUV2RGBA_YUY2","","",50,null],[13,"YUV2BGRA_YUY2","","",50,null],[13,"YUV2RGBA_YVYU","","",50,null],[13,"YUV2BGRA_YVYU","","",50,null],[13,"YUV2GRAY_UYVY","","",50,null],[13,"YUV2GRAY_YUY2","","",50,null],[13,"RGBA2mRGBA","","",50,null],[13,"mRGBA2RGBA","","",50,null],[13,"RGB2YUV_I420","","",50,null],[13,"BGR2YUV_I420","","",50,null],[13,"RGBA2YUV_I420","","",50,null],[13,"BGRA2YUV_I420","","",50,null],[13,"RGB2YUV_YV12","","",50,null],[13,"BGR2YUV_YV12","","",50,null],[13,"RGBA2YUV_YV12","","",50,null],[13,"BGRA2YUV_YV12","","",50,null],[13,"BayerBG2BGR","","",50,null],[13,"BayerGB2BGR","","",50,null],[13,"BayerRG2BGR","","",50,null],[13,"BayerGR2BGR","","",50,null],[13,"BayerBG2GRAY","","",50,null],[13,"BayerGB2GRAY","","",50,null],[13,"BayerRG2GRAY","","",50,null],[13,"BayerGR2GRAY","","",50,null],[13,"BayerBG2BGR_VNG","","",50,null],[13,"BayerGB2BGR_VNG","","",50,null],[13,"BayerRG2BGR_VNG","","",50,null],[13,"BayerGR2BGR_VNG","","",50,null],[13,"BayerBG2BGR_EA","","",50,null],[13,"BayerGB2BGR_EA","","",50,null],[13,"BayerRG2BGR_EA","","",50,null],[13,"BayerGR2BGR_EA","","",50,null],[13,"COLORCVT_MAX","","",50,null],[4,"InterpolationFlag","","Interpolation algorithm",null,null],[13,"InterNearst","","nearest neighbor interpolation",51,null],[13,"InterLinear","","bilinear interpolation",51,null],[13,"InterCubic","","bicubic interpolation",51,null],[13,"InterArea","","resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moire'-free results. But when the image is zoomed, it is similar to the INTER_NEAREST method.",51,null],[13,"InterLanczos4","","Lanczos interpolation over 8x8 neighborhood",51,null],[13,"InterLinearExact","","Bit exact bilinear interpolation",51,null],[13,"InterMax","","mask for interpolation codes",51,null],[13,"WarpFillOutliers","","flag, fills all of the destination image pixels. If some of them correspond to outliers in the source image, they are set to zero",51,null],[13,"WarpInverseMap","","flag, inverse transformation",51,null],[11,"fmt","","",48,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",48,{"i":[{"n":"self"}],"o":{"n":"histogramcomparisionmethod"}}],[11,"eq","","",48,{"i":[{"n":"self"},{"n":"histogramcomparisionmethod"}],"o":{"n":"bool"}}],[11,"hash","","",48,null],[11,"fmt","","",49,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",49,{"i":[{"n":"self"}],"o":{"n":"thresholdtype"}}],[11,"eq","","",49,{"i":[{"n":"self"},{"n":"thresholdtype"}],"o":{"n":"bool"}}],[11,"hash","","",49,null],[11,"fmt","","",50,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",50,{"i":[{"n":"self"}],"o":{"n":"colorconversion"}}],[11,"eq","","",50,{"i":[{"n":"self"},{"n":"colorconversion"}],"o":{"n":"bool"}}],[11,"hash","","",50,null],[11,"fmt","","",51,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",51,{"i":[{"n":"self"}],"o":{"n":"interpolationflag"}}],[11,"eq","","",51,{"i":[{"n":"self"},{"n":"interpolationflag"}],"o":{"n":"bool"}}],[11,"hash","","",51,null],[0,"mat","cv","Mat",null,null],[3,"Mat","cv::mat","The class `Mat` represents an n-dimensional dense numerical single-channel or multi-channel array. It can be used to store real or complex-valued vectors and matrices, grayscale or color images, voxel volumes, vector fields, point clouds, tensors, histograms",null,null],[12,"cols","","Number of columns",52,null],[12,"rows","","Number of rows",52,null],[12,"depth","","Depth of this mat (it should be the type).",52,null],[12,"channels","","Channels of this mat",52,null],[4,"CMat","","The class `CMat` is used as a pointer to represent the Mat opencv structure",null,null],[4,"BorderType","","Various border types, image boundaries are denoted with `|`.",null,null],[13,"Constant","","`iiiiii|abcdefgh|iiiiiii`  with some specified `i`",53,null],[13,"Replicate","","`aaaaaa|abcdefgh|hhhhhhh`",53,null],[13,"Reflect","","`fedcba|abcdefgh|hgfedcb`",53,null],[13,"Wrap","","`cdefgh|abcdefgh|abcdefg`",53,null],[13,"Reflect101","","`gfedcb|abcdefgh|gfedcba`",53,null],[13,"Transparent","","`uvwxyz|abcdefgh|ijklmno`",53,null],[13,"Isolated","","Do not look outside of ROI.",53,null],[11,"clone","","",54,{"i":[{"n":"self"}],"o":{"n":"cmat"}}],[11,"fmt","","",54,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"fmt","","",52,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"into","","",52,{"i":[{"n":"self"}],"o":{"n":"cmat"}}],[11,"from_file_storage","","Loads `Mat` from file storage",52,{"i":[{"n":"p"},{"n":"str"}],"o":{"g":["mat","error"],"n":"result"}}],[11,"new","","Creates an empty `Mat` struct.",52,{"o":{"n":"mat"}}],[11,"from_buffer","","Creates a new `Mat` from buffer. Note that internally opencv function won't take ownership of the Mat, but when we call `drop`, it will deallocate the memory. To prevent double-freeing, you must `mem::forget` it after use.",52,null],[11,"with_size","","Create an empty `Mat` with specific size (rows, cols and types).",52,{"i":[{"n":"c_int"},{"n":"c_int"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"zeros","","Create an empty `Mat` with specific size (rows, cols and types).",52,{"i":[{"n":"c_int"},{"n":"c_int"},{"n":"c_int"}],"o":{"n":"self"}}],[11,"data","","Returns the raw data (as a `u8` pointer)",52,null],[11,"total","","Returns the total number of array elements. The method returns the number of array elements (a number of pixels if the array represents an image). For example, images with 1920x1080 resolution will return 2073600.",52,{"i":[{"n":"self"}],"o":{"n":"usize"}}],[11,"elem_size","","Returns the matrix element size in bytes.",52,{"i":[{"n":"self"}],"o":{"n":"usize"}}],[11,"elem_size1","","Returns the size of each matrix element channel in bytes.",52,{"i":[{"n":"self"}],"o":{"n":"usize"}}],[11,"step1","","Returns a normalized step.",52,{"i":[{"n":"self"},{"n":"c_int"}],"o":{"n":"usize"}}],[11,"size","","Returns the size of this matrix.",52,{"i":[{"n":"self"}],"o":{"n":"size2i"}}],[11,"is_valid","","Check if the `Mat` is valid or not.",52,{"i":[{"n":"self"}],"o":{"n":"bool"}}],[11,"roi","","Return a region of interest from a `Mat` specfied by a `Rect`.",52,{"i":[{"n":"self"},{"n":"rect"}],"o":{"n":"mat"}}],[11,"flip","","Flips an image around vertical, horizontal, or both axes.",52,{"i":[{"n":"self"},{"n":"flipcode"}]}],[11,"cv_type","","Returns the images type. For supported types, please see CvType.",52,{"i":[{"n":"self"}],"o":{"n":"cvtype"}}],[11,"eye","","Returns an identity matrix of the specified size and type.",52,{"i":[{"n":"i32"},{"n":"i32"},{"n":"cvtype"}],"o":{"n":"mat"}}],[11,"at","","Returns individual pixel (element) information within the Mat. This function may need type annotation to assist `FromBytes` trait.",52,{"i":[{"n":"self"},{"n":"i32"}],"o":{"n":"t"}}],[11,"at2","","Returns individual pixel (element) information within the Mat. This function may need type annotation to assist `FromBytes` trait.",52,{"i":[{"n":"self"},{"n":"i32"},{"n":"i32"}],"o":{"n":"t"}}],[11,"at3","","Returns individual pixel (element) information within the Mat. This function may need type annotation to assist `FromBytes` trait.",52,{"i":[{"n":"self"},{"n":"i32"},{"n":"i32"},{"n":"i32"}],"o":{"n":"t"}}],[11,"in_range","","Checks if Mat elements lie between the elements of two other arrays (lowerb and upperb). The output Mat has the same size as `self` and CV_8U type.",52,{"i":[{"n":"self"},{"n":"scalar"},{"n":"scalar"}],"o":{"n":"mat"}}],[11,"min_max_loc","","Finds the global minimum and maximum in an array.",52,null],[11,"mix_channels","","Copy specified channels from `self` to the specified channels of output `Mat`.",52,{"i":[{"n":"self"},{"n":"usize"},{"n":"usize"},{"n":"t"}],"o":{"n":"mat"}}],[11,"normalize","","Normalize the Mat according to the normalization type.",52,{"i":[{"n":"self"},{"n":"f64"},{"n":"f64"},{"n":"normtype"}],"o":{"n":"mat"}}],[11,"count_non_zero","","Counts non-zero array elements.",52,{"i":[{"n":"self"}],"o":{"n":"c_int"}}],[11,"copy_make_border","","Forms a border around an image.",52,{"i":[{"n":"self"},{"n":"i32"},{"n":"i32"},{"n":"i32"},{"n":"i32"},{"n":"bordertype"},{"n":"scalar"}],"o":{"n":"mat"}}],[11,"fmt","","",53,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",53,{"i":[{"n":"self"}],"o":{"n":"bordertype"}}],[18,"Default","","same as Reflect101",53,null],[11,"drop","","",52,{"i":[{"n":"self"}]}],[11,"bitand","","",52,null],[11,"bitor","","",52,null],[11,"bitxor","","",52,null],[11,"not","","",52,null],[11,"clone","","",52,{"i":[{"n":"self"}],"o":{"n":"self"}}],[0,"objdetect","cv","Various object detection algorithms, such as Haar feature-based cascade classifier for object detection and histogram of oriented gradients (HOG).",null,null],[3,"CascadeClassifier","cv::objdetect","Cascade classifier class for object detection.",null,null],[3,"SvmDetector","","SvmDetector",null,null],[3,"HogParams","","Parameters that controls the behavior of HOG.",null,null],[12,"win_size","","Detection window size. Align to block size and block stride. The default is 64x128, trained the same as original paper.",55,null],[12,"block_size","","Block size in pixels. Align to cell size. Only (16,16) is supported for now (at least for GPU).",55,null],[12,"block_stride","","Block stride. It must be a multiple of cell size.",55,null],[12,"cell_size","","Cell size. Only (8, 8) is supported for now.",55,null],[12,"nbins","","Number of bins. Only 9 bins per cell are supported for now.",55,null],[12,"win_sigma","","Gaussian smoothing window parameter. Default -1 for CPU and 4.0 for GPU.",55,null],[12,"l2hys_threshold","","L2-Hys normalization method shrinkage. Default 0.2.",55,null],[12,"gamma_correction","","Flag to specify whether the gamma correction preprocessing is required or not. Default false.",55,null],[12,"nlevels","","Maximum number of detection window increases (HOG scales). Default: 64.",55,null],[12,"hit_threshold","","Threshold for the distance between features and SVM classifying plane. Usually it is 0 and should be specfied in the detector coefficients (as the last free coefficient). But if the free coefficient is omitted (which is allowed), you can specify it manually here.",55,null],[12,"win_stride","","Window stride. It must be a multiple of block stride.",55,null],[12,"padding","","Padding",55,null],[12,"scale","","Coefficient of the detection window increase.",55,null],[12,"group_threshold","","Coefficient to regulate the similarity threshold. When detected, some objects can be covered by many rectangles. 0 means not to perform grouping.",55,null],[12,"use_meanshift_grouping","","The useMeanShiftGrouping parameter is a boolean indicating whether or not mean-shift grouping should be performed to handle potential overlapping bounding boxes. While this value should not be set and users should employ non-maxima suppression instead, we support setting it as a library function.",55,null],[12,"final_threshold","","The `finalThreshold` parameter is mainly used to select the clusters that have at least `finalThreshold + 1` rectangles. This parameter is passed when meanShift is enabled; the function rejects the small clusters containing less than or equal to `finalThreshold` rectangles, computes the average rectangle size for the rest of the accepted clusters and adds those to the output rectangle list.",55,null],[3,"HogDescriptor","","`HogDescriptor` implements Histogram of Oriented Gradients.",null,null],[12,"params","","Hog parameters.",56,null],[4,"CSvmDetector","","Opaque type for C/C++ SvmDetector object",null,null],[8,"ObjectDetect","","An object detect trait.",null,null],[10,"detect","","Detects the object inside this image and returns a list of detections with their confidence.",57,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"vec"}}],[11,"fmt","","",58,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"detect","","",58,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"vec"}}],[11,"new","","Creates a cascade classifier, uninitialized. Before use, call load.",58,{"o":{"n":"cascadeclassifier"}}],[11,"from_path","","Creates a cascade classifier using the model specified.",58,{"i":[{"n":"p"}],"o":{"g":["error"],"n":"result"}}],[11,"load","","Loads the classifier model from a path.",58,{"i":[{"n":"self"},{"n":"p"}],"o":{"g":["error"],"n":"result"}}],[11,"detect_multiscale","","The default detection uses scale factor 1.1, minNeighbors 3, no min size or max size.",58,{"i":[{"n":"self"},{"n":"mat"}],"o":{"g":["rect"],"n":"vec"}}],[11,"detect_with_params","","Detects the object using parameters specified.",58,{"i":[{"n":"self"},{"n":"mat"},{"n":"f32"},{"n":"c_int"},{"n":"size2i"},{"n":"size2i"}],"o":{"g":["rect"],"n":"vec"}}],[11,"drop","","",58,{"i":[{"n":"self"}]}],[11,"fmt","","",59,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",59,{"i":[{"n":"self"}],"o":{"n":"csvmdetector"}}],[11,"fmt","","",60,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"default_people_detector","","The built-in people detector.",60,{"o":{"n":"svmdetector"}}],[11,"daimler_people_detector","","Returns the Daimler people detector.",60,{"o":{"n":"svmdetector"}}],[11,"drop","","",60,{"i":[{"n":"self"}]}],[11,"fmt","","",55,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",55,{"i":[{"n":"self"}],"o":{"n":"hogparams"}}],[11,"default","","",55,{"o":{"n":"hogparams"}}],[11,"fmt","","",56,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"default","","",56,{"o":{"n":"hogdescriptor"}}],[11,"detect","","",56,{"i":[{"n":"self"},{"n":"mat"}],"o":{"n":"vec"}}],[11,"with_params","","Creates a HogDescriptor with provided parameters.",56,{"i":[{"n":"hogparams"}],"o":{"n":"hogdescriptor"}}],[11,"set_svm_detector","","Sets the SVM detector.",56,{"i":[{"n":"self"},{"n":"svmdetector"}]}],[11,"drop","","",56,{"i":[{"n":"self"}]}],[0,"text","cv","Provides different algorithms for text detection and recognition in natural scene images",null,null],[3,"OcrHmmDecoder","cv::text","`OcrHmmDecoder` class provides an interface with the HmmDecoder-ocr API",null,null],[3,"OcrHolisticWord","","`OcrHolisticWord` class provides an interface with the tesseract-ocr API",null,null],[4,"ClassifierType","","",null,null],[13,"Knn","","",61,null],[13,"Cnn","","",61,null],[4,"ComponentLevel","","",null,null],[13,"Word","","",62,null],[13,"TextLine","","",62,null],[11,"fmt","","",61,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",61,{"i":[{"n":"self"}],"o":{"n":"classifiertype"}}],[11,"eq","","",61,{"i":[{"n":"self"},{"n":"classifiertype"}],"o":{"n":"bool"}}],[11,"hash","","",61,null],[11,"fmt","","",63,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates an instance of the `OcrHmmDecoder` class. Initializes HmmDecoder.",63,{"i":[{"n":"p"},{"n":"str"},{"n":"mat"},{"n":"mat"},{"n":"classifiertype"}],"o":{"g":["error"],"n":"result"}}],[11,"drop","","",63,{"i":[{"n":"self"}]}],[11,"fmt","","",64,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","Creates an instance of the `OcrHolisticWord` class.",64,{"i":[{"n":"parch"},{"n":"pweights"},{"n":"pwords"}],"o":{"g":["error"],"n":"result"}}],[11,"drop","","",64,{"i":[{"n":"self"}]}],[8,"OcrImplInterface","","",null,null],[8,"Ocr","","Basic trait for all OCR types",null,null],[10,"run","","Recognize text",65,null],[11,"fmt","","",62,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",62,{"i":[{"n":"self"}],"o":{"n":"componentlevel"}}],[11,"eq","","",62,{"i":[{"n":"self"},{"n":"componentlevel"}],"o":{"n":"bool"}}],[11,"hash","","",62,null],[0,"video","cv","Video Analysis, see OpenCV video",null,null],[0,"tracking","cv::video","Object Tracking, see OpenCV video track",null,null],[11,"camshift","cv::mat","Finds an object center, size, and orientation; returns as `RotatedRect`.",52,{"i":[{"n":"self"},{"n":"rect"},{"n":"termcriteria"}],"o":{"n":"rotatedrect"}}],[0,"analysis","cv::video","Motion Analysis, see OpenCV video motion",null,null],[0,"videoio","cv","Media I/O, see OpenCV videoio",null,null],[3,"VideoCapture","cv::videoio","Video capturing from video files, image sequences or cameras.",null,null],[3,"VideoWriter","","`VideoWriter` provides easy access to write videos to files. -On Linux FFMPEG is used to write videos; -On Windows FFMPEG or VFW is used; -On MacOSX QTKit is used.",null,null],[4,"CapProp","","Video capture's property identifier.",null,null],[13,"PosMsec","","Current position of the video file in milliseconds or video capture timestamp.",66,null],[13,"PosFrames","","0-based index of the frame to be decoded/captured next.",66,null],[13,"PosAviRatio","","Relative position of the video file: 0 - start of the film, 1 - end of the film.",66,null],[13,"FrameWidth","","Width of the frames in the video stream.",66,null],[13,"FrameHeight","","Height of the frames in the video stream.",66,null],[13,"Fps","","Frame rate.",66,null],[13,"Fourcc","","4-character code of codec.",66,null],[13,"FrameCount","","Number of frames in the video file.",66,null],[13,"Format","","Format of the Mat objects returned by retrieve() .",66,null],[13,"Mode","","Backend-specific value indicating the current capture mode.",66,null],[13,"Brightness","","Brightness of the image (only for cameras).",66,null],[13,"Contrast","","Contrast of the image (only for cameras).",66,null],[13,"Saturation","","Saturation of the image (only for cameras).",66,null],[13,"Hue","","Hue of the image (only for cameras).",66,null],[13,"Gain","","Gain of the image (only for cameras).",66,null],[13,"Exposure","","Exposure (only for cameras).",66,null],[13,"ConvertRgb","","Boolean flags indicating whether images should be converted to RGB.",66,null],[13,"WhiteBalanceBlueU","","Currently not supported",66,null],[13,"Rectification","","Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)",66,null],[13,"Monochrome","","",66,null],[13,"Sharpness","","",66,null],[13,"AutoExposure","","",66,null],[13,"Gamma","","",66,null],[13,"Temperature","","",66,null],[13,"Trigger","","",66,null],[13,"TriggerDelay","","",66,null],[13,"WhiteBalanceRedV","","",66,null],[13,"Zoom","","",66,null],[13,"Focus","","",66,null],[13,"Guid","","",66,null],[13,"IsoSpeed","","",66,null],[13,"Backlight","","",66,null],[13,"Pan","","",66,null],[13,"Tilt","","",66,null],[13,"Roll","","",66,null],[13,"Iris","","",66,null],[13,"Settings","","",66,null],[13,"Buffersize","","",66,null],[13,"Autofocus","","",66,null],[4,"VideoWriterProperty","","`VideoWriter`'s property identifier.",null,null],[13,"Quality","","Current quality of the encoded videostream.",67,null],[13,"FrameBytes","","(Read-only) Size of just encoded video frame; note that the encoding order may be different from representation order.",67,null],[13,"NStripes","","Number of stripes for parallel encoding",67,null],[5,"codec_name_from_4cc","","Converts from four character code to `u32`",null,{"i":[{"n":"str"}],"o":{"g":["u32","error"],"n":"result"}}],[5,"codec_name_to_4cc","","Converts to four character code from `u32`.",null,{"i":[{"n":"u32"}],"o":{"n":"string"}}],[11,"fmt","","",68,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"fmt","","",66,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",66,{"i":[{"n":"self"}],"o":{"n":"capprop"}}],[11,"eq","","",66,{"i":[{"n":"self"},{"n":"capprop"}],"o":{"n":"bool"}}],[11,"hash","","",66,null],[11,"new","","Creates a capture device with specified camera id. If there is a single camera connected, just pass 0.",68,{"i":[{"n":"c_int"}],"o":{"n":"self"}}],[11,"from_path","","Creates a capture device with the path of a video file (eg. video.avi). This also supports image sequence, eg. img_%02d.jpg, which will read samples like img_00.jpg, img_01.jpg, img_02.jpg, ...).",68,{"i":[{"n":"str"}],"o":{"n":"self"}}],[11,"is_open","","Returns true if video capturing has been initialized already.",68,{"i":[{"n":"self"}],"o":{"n":"bool"}}],[11,"read","","Grabs, decodes and returns the next video frame. `read` combines `VideoCapture::grab` and `VideoCapture::retrieve` in one call. This is the most convenient method for reading video files or capturing data from decode and return the just grabbed frame.",68,{"i":[{"n":"self"}],"o":{"g":["mat"],"n":"option"}}],[11,"set","","Sets a property in the `VideoCapture`.",68,{"i":[{"n":"self"},{"n":"capprop"},{"n":"f64"}],"o":{"n":"bool"}}],[11,"get","","Gets a property in the `VideoCapture`.",68,{"i":[{"n":"self"},{"n":"capprop"}],"o":{"g":["f64"],"n":"option"}}],[11,"drop","","",68,{"i":[{"n":"self"}]}],[11,"fmt","","",69,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"new","","`VideoWriter` constructor. -path – Name of the output video file. -fourcc – 4-character code of codec used to compress the frames. For  example, VideoWriter::fourcc('P','I','M','1') is a MPEG-1 codec,  VideoWriter::fourcc('M','J','P','G') is a motion-jpeg codec etc. List  of codes can be obtained at Video Codecs by FOURCC page. -fps – Framerate of the created video stream. -frame_size – Size of the video frames. -is_color – If it is not zero, the encoder will expect and encode color  frames, otherwise it will work with grayscale frames (the flag is  currently supported on Windows only).",69,{"i":[{"n":"str"},{"n":"c_int"},{"n":"f64"},{"n":"size2i"},{"n":"bool"}],"o":{"n":"videowriter"}}],[11,"open","","`VideoWriter` constructor. -path – Name of the output video file. -fourcc – 4-character code of codec used to compress the frames. For  example, VideoWriter::fourcc('P','I','M','1') is a MPEG-1 codec,  VideoWriter::fourcc('M','J','P','G') is a motion-jpeg codec etc. List  of codes can be obtained at Video Codecs by FOURCC page. -fps – Framerate of the created video stream. -frame_size – Size of the video frames. -is_color – If it is not zero, the encoder will expect and encode color  frames, otherwise it will work with grayscale frames (the flag is  currently supported on Windows only).",69,{"i":[{"n":"self"},{"n":"str"},{"n":"c_int"},{"n":"f64"},{"n":"size2i"},{"n":"bool"}],"o":{"n":"bool"}}],[11,"write","","Writes the specified image to video file. It must have the same size as has been specified when opening the video writer.",69,{"i":[{"n":"self"},{"n":"mat"}]}],[11,"is_open","","Returns true if video writer has been initialized already.",69,{"i":[{"n":"self"}],"o":{"n":"bool"}}],[11,"set","","Sets a property in the `VideoWriter`. Note: `VideoWriterProperty::FrameBytes` is read-only.",69,{"i":[{"n":"self"},{"n":"videowriterproperty"},{"n":"f64"}],"o":{"n":"bool"}}],[11,"get","","Gets a property in the `VideoWriter`.",69,{"i":[{"n":"self"},{"n":"videowriterproperty"}],"o":{"g":["f64"],"n":"option"}}],[11,"default","","",69,{"o":{"n":"videowriter"}}],[11,"drop","","",69,{"i":[{"n":"self"}]}],[11,"fmt","","",67,{"i":[{"n":"self"},{"n":"formatter"}],"o":{"n":"result"}}],[11,"clone","","",67,{"i":[{"n":"self"}],"o":{"n":"videowriterproperty"}}],[11,"eq","","",67,{"i":[{"n":"self"},{"n":"videowriterproperty"}],"o":{"n":"bool"}}],[11,"hash","","",67,null],[14,"path_to_cstring","cv","",null,null],[14,"string_to_cstring","","",null,null],[11,"from","cv::mat","",52,{"i":[{"n":"gpumat"}],"o":{"n":"mat"}}],[11,"show","","",52,{"i":[{"n":"self"},{"n":"str"},{"n":"c_int"}],"o":{"g":["error"],"n":"result"}}],[11,"image_decode","","Decodes an image from `buf` according to the specified mode.",52,null],[11,"image_encode","","Encodes an image; the encoding scheme depends on the extension provided; additional write flags can be passed in using a vector. If successful, returns an owned vector of the encoded image.",52,{"i":[{"n":"self"},{"n":"str"},{"g":["imagewritemode"],"n":"vec"}],"o":{"g":["vec","error"],"n":"result"}}],[11,"from_path","","Creates a `Mat` from reading the image specified by the path.",52,{"i":[{"n":"p"},{"n":"imagereadmode"}],"o":{"g":["mat","error"],"n":"result"}}],[11,"line","","Draws a simple line.",52,{"i":[{"n":"self"},{"n":"point2i"},{"n":"point2i"}]}],[11,"line_custom","","Draws a line with custom color, thickness and linetype.",52,{"i":[{"n":"self"},{"n":"point2i"},{"n":"point2i"},{"n":"scalar"},{"n":"c_int"},{"n":"linetype"},{"n":"c_int"}]}],[11,"rectangle","","Draws a simple, thick, or filled up-right rectangle.",52,{"i":[{"n":"self"},{"n":"rect"}]}],[11,"rectangle_custom","","Draws a rectangle with custom color, thickness and linetype.",52,{"i":[{"n":"self"},{"n":"rect"},{"n":"scalar"},{"n":"c_int"},{"n":"linetype"}]}],[11,"rectangle2f","","Draw a simple, thick, or filled up-right rectangle.",52,{"i":[{"n":"self"},{"n":"rect2f"}]}],[11,"ellipse","","Draws a simple, thick ellipse",52,{"i":[{"n":"self"},{"n":"point2i"},{"n":"size2i"},{"n":"f64"},{"n":"f64"},{"n":"f64"}]}],[11,"ellipse_custom","","Draws a custom ellipse",52,{"i":[{"n":"self"},{"n":"point2i"},{"n":"size2i"},{"n":"f64"},{"n":"f64"},{"n":"f64"},{"n":"scalar"},{"n":"c_int"},{"n":"linetype"},{"n":"c_int"}]}],[11,"cvt_color","","Convert an image from one color space to another.",52,{"i":[{"n":"self"},{"n":"colorconversion"}],"o":{"n":"mat"}}],[11,"pyr_down","","Blurs an image and downsamples it. This function performs the downsampling step of the Gaussian pyramid construction.",52,{"i":[{"n":"self"}],"o":{"n":"mat"}}],[11,"threshold","","Threshold",52,{"i":[{"n":"self"},{"n":"f64"},{"n":"f64"},{"n":"thresholdtype"}],"o":{"n":"mat"}}],[11,"erode","","Erode",52,{"i":[{"n":"self"},{"n":"mat"},{"n":"point2i"},{"n":"i32"},{"n":"bordertype"},{"n":"scalar"}],"o":{"n":"mat"}}],[11,"dilate","","Dilate",52,{"i":[{"n":"self"},{"n":"mat"},{"n":"point2i"},{"n":"i32"},{"n":"bordertype"},{"n":"scalar"}],"o":{"n":"mat"}}],[11,"gaussian_blur","","Gaussian Blur",52,{"i":[{"n":"self"},{"n":"size2i"},{"n":"f64"},{"n":"f64"},{"n":"bordertype"}],"o":{"n":"mat"}}],[11,"resize_to","","Resizes an image.",52,{"i":[{"n":"self"},{"n":"size2i"},{"n":"interpolationflag"}],"o":{"n":"mat"}}],[11,"resize_by","","Resizes an image.",52,{"i":[{"n":"self"},{"n":"f64"},{"n":"f64"},{"n":"interpolationflag"}],"o":{"n":"mat"}}],[11,"calc_hist","","Calculate a histogram of an image.",52,{"i":[{"n":"self"},{"n":"t"},{"n":"mat"},{"n":"u"},{"n":"m"}],"o":{"n":"mat"}}],[11,"calc_back_project","","Calculate the back projection of a histogram. The function calculates the back project of the histogram.",52,{"i":[{"n":"self"},{"n":"t"},{"n":"mat"},{"n":"m"}],"o":{"n":"mat"}}],[11,"compare_hist","","Compares two histograms. The function compare two histograms using the specified method. The function returns d(first_image, second_image). While the function works well with 1-, 2-, 3-dimensional dense histograms, it may not be suitable for high-dimensional sparse histograms. In such histograms, because of aliasing and sampling problems, the coordinates of non-zero histogram bins can slightly shift. To compare such histograms or more general sparse configurations of weighted points, consider using the cv::EMD function.",52,{"i":[{"n":"self"},{"n":"mat"},{"n":"histogramcomparisionmethod"}],"o":{"g":["f64","string"],"n":"result"}}]],"paths":[[3,"KeyPoint"],[3,"Point2i"],[3,"Point2f"],[3,"Size2i"],[3,"Size2f"],[3,"Rect"],[3,"Rect2f"],[4,"LineType"],[4,"FlipCode"],[4,"CvType"],[4,"NormType"],[4,"TermType"],[8,"FromBytes"],[3,"Scalar"],[3,"RotatedRect"],[3,"TermCriteria"],[3,"GpuMat"],[3,"GpuHog"],[4,"CGpuMat"],[4,"CGpuHog"],[4,"CGpuCascade"],[3,"GpuCascade"],[4,"CvError"],[4,"KMeansCenters"],[4,"DescriptorMatcherType"],[3,"BOWKMeansTrainer"],[3,"DMatch"],[3,"DescriptorMatcher"],[3,"MSER"],[3,"MSERBuilder"],[3,"SIFT"],[3,"SIFTBuilder"],[3,"SURF"],[3,"SURFBuilder"],[8,"Feature2D"],[8,"Hash"],[3,"AverageHash"],[3,"BlockMeanHash"],[3,"ColorMomentHash"],[3,"MarrHildrethHash"],[3,"PHash"],[3,"RadialVarianceHash"],[4,"WindowFlag"],[4,"MouseEventType"],[8,"Show"],[4,"ImageReadMode"],[4,"ImageWriteMode"],[4,"ImageWritePngStrategy"],[4,"HistogramComparisionMethod"],[4,"ThresholdType"],[4,"ColorConversion"],[4,"InterpolationFlag"],[3,"Mat"],[4,"BorderType"],[4,"CMat"],[3,"HogParams"],[3,"HogDescriptor"],[8,"ObjectDetect"],[3,"CascadeClassifier"],[4,"CSvmDetector"],[3,"SvmDetector"],[4,"ClassifierType"],[4,"ComponentLevel"],[3,"OcrHmmDecoder"],[3,"OcrHolisticWord"],[8,"Ocr"],[4,"CapProp"],[4,"VideoWriterProperty"],[3,"VideoCapture"],[3,"VideoWriter"]]};
initSearch(searchIndex);
